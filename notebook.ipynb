{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Comparing a data set using 3 different classification models</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "<p>The advancement of vehicular technology and the proliferation of sensors have paved the way for sophisticated analysis of driving behavior, road conditions, and traffic patterns. This study leverages sensor data from two types of vehicles, Opel Corsa and Peugeot 207, to classify driving styles, road surface conditions, and traffic congestion. By comparing three classification algorithms—Support Vector Machine (SVM), Logistic Regression, and k-Nearest Neighbors (kNN)—this paper aims to identify the most effective model for interpreting complex, real-world driving data. The chosen datasets, sourced from Kaggle, present a realistic challenge with issues such as missing values and non-standard numeric formats, requiring thorough preprocessing and analysis.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Pre-Processing</h3>\n",
    "\n",
    "<p>The initial step involved converting the datasets' numeric formats from decimal commas to decimal points and addressing missing values. Given the datasets' omission of average speed for the first 60 samples, these entries were excluded from the analysis. Further cleaning included the removal of outliers and normalization of features to ensure model accuracy.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Analysis and Visulalisation</h3>\n",
    "\n",
    "<p>Preliminary data analysis was conducted to understand the datasets' characteristics, including distribution of variables, correlation between features, and potential data imbalances. Visualisations such as histograms, scatter plots, and correlation matrices were employed to identify patterns and anomalies in the data. This exploratory phase informed the subsequent feature selection and engineering process, highlighting the variables most relevant to driving style, road condition, and traffic congestion classification.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classifier Models</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4>Support Vector Machine (SVM)</h4>\n",
    "<p>The SVM classifier is known for its effectiveness in high-dimensional spaces, making it suitable for our dataset with multiple sensor readings. We employed both linear and radial basis function (RBF) kernels to evaluate the model's performance across different complexity levels. The choice of kernel significantly impacts the decision boundary, with the RBF kernel offering flexibility in handling non-linear data relationships[1].</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic Regressions</h3>\n",
    "\n",
    "<p>As a probabilistic statistical model, Logistic Regression was applied due to its simplicity and efficiency in binary classification problems. It was particularly useful in classifying driving styles into 'Even Pace' and 'Aggressive' categories. The model's output, the probability score, facilitated the interpretation of results, providing insights into the likelihood of each driving style[2].</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>k-Nearest Neighbors (kNN)</h3>\n",
    "\n",
    "<p>The kNN algorithm, with its non-parametric nature, was chosen for its intuitiveness and ease of implementation. The algorithm's performance was assessed with various values of 'k' to find the optimal balance between bias and variance. kNN's reliance on the proximity of samples makes it sensitive to the feature space's scale, underscoring the importance of prior data scaling[3]. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Experiment and Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross-Validation Approach</h3>\n",
    "\n",
    "To ensure the robustness of our model evaluations, we employed k-fold cross-validation. This method allowed us to utilize every data point in both training and testing phases, providing a comprehensive assessment of each model's performance across different subsets of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Performance Metrics</h3>\n",
    "\n",
    "We compared the models based on accuracy, precision, recall, and F1 score. These metrics provided a holistic view of each classifier's strengths and weaknesses, especially in handling imbalanced datasets[4].\n",
    "\n",
    "- SVM showed high precision but lower recall, indicating a conservative classification strategy.\n",
    "- Logistic Regression exhibited balanced performance across all metrics, highlighting its versatility.\n",
    "- kNN's performance was sensitive to the choice of 'k', with an optimal value offering competitive accuracy and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Result Analysis</h3>\n",
    "\n",
    "Visualization of the results included confusion matrices and ROC curves. These visual aids helped in interpreting the models' performance, particularly in identifying false positives and negatives. The analysis revealed that while SVM and kNN excelled in specific scenarios, Logistic Regression provided the most consistent results across various metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our comparative analysis of SVM, Logistic Regression, and kNN on vehicle sensor data highlights the importance of choosing an appropriate model based on the specific classification task and data characteristics. Logistic Regression emerged as a versatile and robust classifier, offering consistent performance across different evaluation metrics. Future work could explore ensemble methods and deep learning approaches to further improve classification accuracy and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "1. Cortes, C., & Vapnik, V. (1995). *Support-vector networks*. Machine Learning, 20(3), 273-297.\n",
    "2. McCullagh, P., & Nelder, J. A. (1989). *Generalized Linear Models*. Chapman and Hall.\n",
    "3. Cover, T., & Hart, P. (1967). Nearest neighbor pattern classification. IEEE Transactions on Information Theory, 13(1), 21-27.\n",
    "4. Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861-874.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
